{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and load necesary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't change this cell\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>298</td>\n",
       "      <td>474</td>\n",
       "      <td>4</td>\n",
       "      <td>884182806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>115</td>\n",
       "      <td>265</td>\n",
       "      <td>2</td>\n",
       "      <td>881171488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>253</td>\n",
       "      <td>465</td>\n",
       "      <td>5</td>\n",
       "      <td>891628467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "1      186      302       3  891717742\n",
       "3      244       51       2  880606923\n",
       "5      298      474       4  884182806\n",
       "6      115      265       2  881171488\n",
       "7      253      465       5  891628467"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please don't change this cell\n",
    "\n",
    "df = pd.read_csv('ml-100k/u.data', names=['user_id', 'item_id', 'rating', 'timestamp'], sep='\\t')\n",
    "\n",
    "# obtain top 500 users and top 500 items\n",
    "user_ids = df.groupby('user_id').count().sort_values(by='rating', ascending=False).head(500).index\n",
    "item_ids = df.groupby('item_id').count().sort_values(by='rating', ascending=False).head(500).index\n",
    "df = df[(df['user_id'].isin(user_ids)) & (df['item_id'].isin(item_ids))]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly select one rating from each user as test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't change this cell\n",
    "\n",
    "# remap user and item ID\n",
    "df['user_id'] = df.groupby('user_id').ngroup()\n",
    "df['item_id'] = df.groupby('item_id').ngroup()\n",
    "\n",
    "test_df = df.groupby('user_id').sample(1, random_state=1024)\n",
    "train_df = df[~df.index.isin(test_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of users: 500\n",
      "The number of items: 500\n",
      "Avg. # of rated Items/User: 129.914\n",
      "Density of data: 0.259828\n",
      "Ratings Range: 1 - 5\n"
     ]
    }
   ],
   "source": [
    "# Please don't change this cell\n",
    "\n",
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "avg_num = df.groupby('user_id').size().mean()\n",
    "density = df.shape[0] / (n_users * n_items)\n",
    "min_ratings = df.rating.min()\n",
    "max_ratings = df.rating.max()\n",
    "\n",
    "print(\"The number of users: {}\" .format(n_users))\n",
    "print(\"The number of items: {}\" .format(n_items))\n",
    "print(\"Avg. # of rated Items/User: {}\" .format(avg_num))\n",
    "print(\"Density of data: {}\" .format(density))\n",
    "print(\"Ratings Range: {} - {}\" .format(min_ratings, max_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construct the rating matrix based on train_df:\n",
      "[[5. 3. 4. ... 0. 0. 0.]\n",
      " [4. 0. 0. ... 0. 0. 0.]\n",
      " [4. 3. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 5. 0. ... 0. 4. 0.]]\n",
      "Construct the rating matrix based on test_df:\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Please don't change this cell\n",
    "\n",
    "# Convert the format of datasets to matrices\n",
    "# Train dataset\n",
    "df_zeros = pd.DataFrame({\n",
    "    'user_id': np.tile(np.arange(0, n_users), n_items), \n",
    "    'item_id': np.repeat(np.arange(0, n_items), n_users), \n",
    "    'rating': 0})\n",
    "train_ds = df_zeros.merge(train_df, \n",
    "                          how='left', \n",
    "                          on=['user_id', 'item_id']).fillna(0.).pivot_table(\n",
    "                              values='rating_y', \n",
    "                              index='user_id', \n",
    "                              columns='item_id').values\n",
    "                           \n",
    "# Test dataset\n",
    "test_ds = df_zeros.merge(test_df, \n",
    "                         how='left', \n",
    "                         on=['user_id', 'item_id']).fillna(0.).pivot_table(\n",
    "                             values='rating_y', \n",
    "                             index='user_id', \n",
    "                             columns='item_id').values\n",
    "\n",
    "print(\"Construct the rating matrix based on train_df:\")\n",
    "print(train_ds)\n",
    "\n",
    "print(\"Construct the rating matrix based on test_df:\")\n",
    "print(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't change this cell\n",
    "EPSILON = 1e-9\n",
    "\n",
    "def user_corr(imputed_train_ds):\n",
    "    '''\n",
    "    Function for calculating user's similarity\n",
    "    '''\n",
    "    active_user_pearson_corr = np.zeros((imputed_train_ds.shape[0], imputed_train_ds.shape[0]))\n",
    "\n",
    "    # Compute Pearson Correlation Coefficient of All Pairs of Users between active set and training dataset\n",
    "    for i, user_i_vec in enumerate(imputed_train_ds):\n",
    "        for j, user_j_vec in enumerate(imputed_train_ds):\n",
    "\n",
    "            # ratings corated by the current pair od users\n",
    "            mask_i = user_i_vec > 0\n",
    "            mask_j = user_j_vec > 0\n",
    "\n",
    "            # corrated item index, skip if there are no corrated ratings\n",
    "            corrated_index = np.intersect1d(np.where(mask_i), np.where(mask_j))\n",
    "            if len(corrated_index) == 0:\n",
    "                continue\n",
    "\n",
    "            # average value of user_i_vec and user_j_vec\n",
    "            mean_user_i = np.sum(user_i_vec) / (np.sum(np.clip(user_i_vec, 0, 1)) + EPSILON)\n",
    "            mean_user_j = np.sum(user_j_vec) / (np.sum(np.clip(user_j_vec, 0, 1)) + EPSILON)\n",
    "\n",
    "            # compute pearson corr\n",
    "            user_i_sub_mean = user_i_vec[corrated_index] - mean_user_i\n",
    "            user_j_sub_mean = user_j_vec[corrated_index] - mean_user_j\n",
    "\n",
    "            r_ui_sub_r_i_sq = np.square(user_i_sub_mean)\n",
    "            r_uj_sub_r_j_sq = np.square(user_j_sub_mean)\n",
    "\n",
    "            r_ui_sum_sqrt = np.sqrt(np.sum(r_ui_sub_r_i_sq))\n",
    "            r_uj_sum_sqrt = np.sqrt(np.sum(r_uj_sub_r_j_sq))\n",
    "\n",
    "            sim = np.sum(user_i_sub_mean * user_j_sub_mean) / (r_ui_sum_sqrt * r_uj_sum_sqrt + EPSILON)\n",
    "            active_user_pearson_corr[i][j] = sim\n",
    "\n",
    "    return active_user_pearson_corr\n",
    "\n",
    "def predict(test_ds, imputed_train_ds, user_corr, k=20):\n",
    "    '''\n",
    "    Function for predicting ratings in test_ds\n",
    "    '''\n",
    "\n",
    "    # Predicting ratings of test set\n",
    "    predicted_ds = np.zeros_like(test_ds)\n",
    "\n",
    "    for (i, j), rating in np.ndenumerate(test_ds):\n",
    "\n",
    "        if rating > 0:\n",
    "\n",
    "            # only predict ratings on test set\n",
    "            sim_user_ids = np.argsort(user_corr[i])[-1:-(k + 1):-1]\n",
    "\n",
    "            #==================user-based==================#\n",
    "            # the coefficient values of similar users\n",
    "            sim_val = user_corr[i][sim_user_ids]\n",
    "\n",
    "            # the average value of the current user's ratings\n",
    "            sim_users = imputed_train_ds[sim_user_ids]\n",
    "            \n",
    "            mask_rateditem_user = imputed_train_ds[i] != 0\n",
    "            num_rated_items = mask_rateditem_user.astype(np.float32)\n",
    "            user_mean = np.sum(imputed_train_ds[i, mask_rateditem_user]) / (num_rated_items.sum() + EPSILON)\n",
    "\n",
    "            mask_nei_rated_items = sim_users != 0\n",
    "            num_rated_per_user = mask_nei_rated_items.astype(np.float32)\n",
    "            num_per_user = num_rated_per_user.sum(axis=1)\n",
    "\n",
    "            sum_per_user = sim_users.sum(axis=1)\n",
    "            sim_user_mean = sum_per_user / (num_per_user + EPSILON)\n",
    "            \n",
    "            mask_rated_j = sim_users[:, j] > 0\n",
    "                            \n",
    "            # sim(u, v) * (r_vj - mean_v)\n",
    "            sim_r_sum_mean = sim_val[mask_rated_j] * (sim_users[mask_rated_j, j] - sim_user_mean[mask_rated_j])\n",
    "            \n",
    "            user_based_pred = user_mean + np.sum(sim_r_sum_mean) / (np.sum(sim_val[mask_rated_j]) + EPSILON)\n",
    "\n",
    "            predicted_ds[i, j] = np.clip(user_based_pred, 0, 5)\n",
    "            \n",
    "    return predicted_ds\n",
    "\n",
    "def evaluate(test_ds, predicted_ds):\n",
    "    '''\n",
    "    Function for evaluating on MAE and RMSE\n",
    "    '''\n",
    "    # MAE\n",
    "    mask_test_ds = test_ds > 0\n",
    "    MAE = np.sum(np.abs(test_ds[mask_test_ds] - predicted_ds[mask_test_ds])) / np.sum(mask_test_ds.astype(np.float32))\n",
    "\n",
    "    # RMSE\n",
    "    RMSE = np.sqrt(np.sum(np.square(test_ds[mask_test_ds] - predicted_ds[mask_test_ds])) / np.sum(mask_test_ds.astype(np.float32)))\n",
    "\n",
    "    return MAE, RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline - KNN based recommendation (Similarity Metric: Pearson Correlation Coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't change this cell\n",
    "\n",
    "user_pearson_corr = user_corr(train_ds)\n",
    "predicted_ds = predict(test_ds, train_ds, user_pearson_corr, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== Baseline Result =====================\n",
      "MAE: 0.8471711011333851, RMSE: 1.092846045041526\n"
     ]
    }
   ],
   "source": [
    "# Please don't change this cell\n",
    "\n",
    "MAE, RMSE = evaluate(test_ds, predicted_ds)\n",
    "\n",
    "print(\"===================== Baseline Result =====================\")\n",
    "print(\"MAE: {}, RMSE: {}\" .format(MAE, RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Solution\n",
    "(Put all your implementation for your solution in the following cell only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "# You are required to implement the existing solution in the given report here. \n",
    "# Then, evaluate your implementation by predicting the ratings in the test set (test_ds).\n",
    "# Finally, save the corresponding MAE and RMSE of your implementation \n",
    "# into the following defined corresponding variable. \n",
    "\n",
    "# A. Item's Popularity Computation\n",
    "# - Calculating number of times each item has been rated\n",
    "P = np.sum(np.count_nonzero(train_ds, axis=0))\n",
    "\n",
    "# B. User's Similarity Computation and KNN Selection\n",
    "# creating a matrix for item similarity\n",
    "user_corr = np.zeros((n_items, n_items))\n",
    "\n",
    "for a, user_a_vec in enumerate(train_ds):\n",
    "    for u, user_u_vec in enumerate(train_ds):\n",
    "        # mask returns true if rating is there (so greater than 0)\n",
    "        mask_a = user_a_vec > 0\n",
    "        mask_u = user_u_vec > 0\n",
    "\n",
    "#   a) Ratings data making up\n",
    "#      STEP 1:\n",
    "#      - Calculating the union set of items voted by user a or user b\n",
    "#      - Stores the index where either user a or user u has rated the item\n",
    "        union_set = np.union1d(np.where(mask_a), np.where(mask_u))\n",
    "    \n",
    "        # if there isn't at least one item rated by either user a or user u, move on to the next\n",
    "        if len(union_set) == 0:\n",
    "            continue\n",
    "\n",
    "#      STEP 2:\n",
    "#      - For each item in the union set, if user a or user u haven't rated the item, predict\n",
    "#        the missing value as the average rating of the corresponding user\n",
    "\n",
    "#      - average ratings by of user_a_vec and user_u_vec\n",
    "        mean_user_a = np.sum(user_a_vec) / (np.sum(np.clip(user_a_vec, 0, 1)) + EPSILON)\n",
    "        mean_user_u = np.sum(user_u_vec) / (np.sum(np.clip(user_u_vec, 0, 1)) + EPSILON)\n",
    "\n",
    "        # if value is not rated from union set, replacing it with the corresponding average rating\n",
    "        for index in union_set:\n",
    "            if user_a_vec[index] == 0:\n",
    "                user_a_vec[index] = mean_user_a\n",
    "            if user_u_vec[index] == 0:\n",
    "                user_u_vec[index] = mean_user_u\n",
    "        \n",
    "        # new vector with only the items in the union set and the replaced missing values\n",
    "        new_user_a_vec = user_a_vec[union_set]\n",
    "        new_user_u_vec = user_u_vec[union_set]\n",
    "\n",
    "#   b) Similarity computation utilizing itemâ€™s popularity\n",
    "#      - w = log(m/P) , where m = number of users\n",
    "        m = n_users\n",
    "        w = np.log(m / P)\n",
    "        \n",
    "        # calculating number for the formula\n",
    "        numerator = np.sum(np.square(w) * (new_user_a_vec - mean_user_a) * (new_user_u_vec - mean_user_u))\n",
    "        \n",
    "        # caculating the square values for the denominator\n",
    "        denominator_a = np.sqrt(np.sum(np.square(w) * np.square(new_user_a_vec - mean_user_a)))\n",
    "        denominator_u = np.sqrt(np.sum(np.square(w) * np.square(new_user_u_vec - mean_user_u)))\n",
    "        \n",
    "        # multiplying both values to get final d\n",
    "        denominator = denominator_a * denominator_u  + EPSILON\n",
    "        \n",
    "        # finding the similarity\n",
    "        sim_a_u = numerator / denominator\n",
    "        \n",
    "        # adding similarity to the matrix\n",
    "        user_corr[a][u] = sim_a_u\n",
    "\n",
    "        \n",
    "# creating matrix to store the prediction ratings\n",
    "prediction_ratings = np.zeros_like(test_ds)\n",
    "\n",
    "k = 20\n",
    "for (a, u), rating in np.ndenumerate(test_ds):\n",
    "#   c) K-Nearest Neighbours Selection\n",
    "       # finding the similar items based on the k value\n",
    "       # and sorts in descending order\n",
    "       # gets the user ids\n",
    "       # removed the user itself (as user is most similar to itself)\n",
    "    knn_sim_users = np.argsort(user_corr[a])[-1:-(k + 1):-1]\n",
    "    \n",
    "    \n",
    "#   C. Prediction and Recommendation for Active Users\n",
    "#      - Calculate predictions based on the formula provided in the report\n",
    "    # uses the similar items to calculate the coefficient values\n",
    "    sim_values = user_corr[a][knn_sim_users]\n",
    "    \n",
    "    # calculates the mean for the rating of the current user\n",
    "    sim_users = train_ds[knn_sim_users]\n",
    "    \n",
    "    # creates mask for items user a based on if they have rated an item or not\n",
    "    mask_rateditem_user = train_ds[a] != 0\n",
    "    # calculates number of items rated (first converts boolean to floats - True = 1.0, False = 0.0)\n",
    "    num_rated_items = mask_rateditem_user.astype(np.float32).sum()\n",
    "    # calculates the mean rating for the user\n",
    "    user_mean = np.sum(train_ds[a, mask_rateditem_user]) / (num_rated_items + EPSILON)\n",
    "    \n",
    "    # created mask based on whether the mean rating for similar users is a zero or not\n",
    "    mask_nei_rated_items = sim_users != 0\n",
    "    # converts boolean values to floats (True = 1.0, False = 0.0)\n",
    "    # then, calculates the number of items rated by the user\n",
    "    num_per_user = mask_nei_rated_items.astype(np.float32).sum(axis = 1)\n",
    "  \n",
    "    \n",
    "    # number of similar users per user\n",
    "    sum_per_user = sim_users.sum(axis=1)\n",
    "    # mean number of users\n",
    "    sim_user_mean = sum_per_user / (num_per_user + EPSILON)\n",
    "    \n",
    "    mask_rated_u = sim_users[:, u] > 0\n",
    "                            \n",
    "    # sim(a, u) * (R(u, i) - mean of R(u))\n",
    "    sim_r_sum_mean = sim_values[mask_rated_u] * (sim_users[mask_rated_u, u] - sim_user_mean[mask_rated_u])\n",
    "            \n",
    "    # calculated prediction (mean + sim(a, u) * R(u, i) - mean of R(u)) / sum(a,u))\n",
    "    user_based_pred = user_mean + np.sum(sim_r_sum_mean) / (np.sum(sim_values[mask_rated_u]) + EPSILON)\n",
    "    \n",
    "    # adds prediction to rating\n",
    "    # as prediction needs to be between 0 and 5 and value smaller than 0 gets a 0 prediction\n",
    "    # and any value greater than 5 gets a 5 prediction\n",
    "    prediction_ratings[a, u] = np.clip(user_based_pred, 0, 5)\n",
    "    \n",
    "# use the evaluate function provided to get the MAE and RMSE values\n",
    "MAE, RMSE = evaluate(test_ds, prediction_ratings)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the MAE and RMSE of Your Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== The MAE and RMSE of Your Implementation =====================\n",
      "MAE: 0.7678874649435112, RMSE: 0.9650219034614862\n"
     ]
    }
   ],
   "source": [
    "# Please don't change this cell\n",
    "\n",
    "print(\"===================== The MAE and RMSE of Your Implementation =====================\")\n",
    "print(\"MAE: {}, RMSE: {}\" .format(MAE, RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
